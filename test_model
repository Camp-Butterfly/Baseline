# -*- coding: utf-8 -*-
"""Analysis of TestModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nxtieCmLZXyZvx017CSal7sesY_VaCc9

Import Libraries
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Commented out IPython magic to ensure Python compatibility.
try:
  # Use the %tensorflow_version magic if in colab.
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf

from tensorflow.keras.preprocessing.image import ImageDataGenerator

import os
import glob
import shutil
import numpy as np
import matplotlib.pyplot as plt

"""Mount Google Drive"""

# Load the Drive helper and mount
from google.colab import drive

# This will prompt for authorization.
drive.mount('/folders/')

"""Take data and divide into Train(70), Test(15), Validation(15) sets."""

#list folders in target directory to double check and set as base directory

base_directory = "/folders/My Drive/ButterflyDataset"
!ls "/folders/My Drive/ButterflyDataset/train"

#create labels for classes

classes = ['cabbage','ringlet','sulphur','monarch-milkweed']

#create training, test, validation sets from existing data
for cl in classes:
  print(cl)
  #cl_new = cl + "/croppedphotos"
  cl_new = cl + "/cleanphotos"
  image_path = os.path.join(base_directory, cl_new)
  print(image_path)
  #use glob extension to loop through image files
  images = glob.glob(image_path + '/*.JPEG')
  print("{}: {} Images".format(cl, len(images)))
  #from 0 - .7 of images, from .7 - .7+.15 of images, from .7+.15-100 of images
  train,val,test = images[:round(len(images)*0.7)], images[round(len(images)*0.7):round(len(images)*0.85)], images[round(len(images)*.85):]
  print(len(val))
  print(os.path.join(base_directory, 'val', cl))
  # for v in val:
  #   shutil.copy(v, os.path.join(base_directory, 'val', cl))
  # print("done with " + cl + " val" )
  # for ts in test:
  #   shutil.copy(ts, os.path.join(base_directory, 'test', cl))
  # print("done with " + cl + " test" )

  
  
  # for t in train:
  #   shutil.copy(t,os.path.join(base_directory, 'train', cl))
  # print("done with " + cl + " train" )

print(train)

#set up paths to training, validation, and test directories

train_dir = os.path.join(base_directory,'train') 
print(train_dir)
val_dir = os.path.join(base_directory,'val')
test_dir = os.path.join(base_directory,'test')

"""TO DO: ADD DATA AUGMENTATION HERE

Create CNN Here
"""

#Define macro values here
BATCH_SIZE = 100  # Number of training examples to process before updating our models variables
IMG_SHAPE  = 150  # Our training data consists of images with width of 150 pixels and height of 150 pixels

#rescale RBG values from 0-255 to 0-1
train_image_generator      = ImageDataGenerator(rescale=1./255)  # Generator for our training data
validation_image_generator = ImageDataGenerator(rescale=1./255)  # Generator for our validation data

# #use "flow_from_directory" function to rescale and resize images
# train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
#                                                            directory=train_dir,
#                                                            shuffle=True,
#                                                            target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)
#                                                            class_mode='sparse')

#Generate batches of tensor image data. We feed in our paths to our images and the generator will 
#apply our data augmentation functions to batch size chucks for all the classes of our images.
# we do data augmentation to prevent overfitting

image_gen_train = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=45,
                    width_shift_range=.15,
                    height_shift_range=.15,
                    horizontal_flip=True,
                    zoom_range=0.5
                    )


train_data_gen = image_gen_train.flow_from_directory(
                                                batch_size=BATCH_SIZE,
                                                directory=train_dir,
                                                shuffle=True,
                                                target_size=(IMG_SHAPE,IMG_SHAPE),
                                                class_mode='sparse'
                                                )


# # val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
#                                                               directory=val_dir,
#                                                               shuffle=False,
#                                                               target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)
#                                                               class_mode='sparse')

image_gen_val = ImageDataGenerator(rescale=1./255)

val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,
                                                 directory=val_dir,
                                                 target_size=(IMG_SHAPE, IMG_SHAPE),
                                                 class_mode='sparse')

#import regularizer
from keras import regularizers

model = tf.keras.models.Sequential([
    #convolution layer 16 outputs to one image input 
    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(150, 150, 3)),
    #downsampling image
    tf.keras.layers.MaxPooling2D(2, 2),
    #convolution layer 32 outputs to one image input 
    tf.keras.layers.Conv2D(32, 3,kernel_regularizer=regularizers.l2(0.01), padding='same', activation='relu'),
    #downsampling image
    tf.keras.layers.MaxPooling2D(2,2),
    #convolution layer 64 outputs to one image input 
    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
    #downsampling image
    tf.keras.layers.MaxPooling2D(2,2),
    
    # flattens to 1d array
    tf.keras.layers.Flatten(),
    #Dropout of 20% to prevent over fitting (turns off some neurons)
    tf.keras.layers.Dropout(0.2),
    
    tf.keras.layers.Dense(512, kernel_regularizer=regularizers.l2(0.01), activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(4, activation='softmax')
])

# ADD BATCH NORMALIZATION

#compile model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

#model summary
model.summary()

#num_nymphalid_tr = len(os.listdir(os.path.join(base_directory,'train/nymphalid')))
num_sulphur_tr = len(os.listdir(os.path.join(base_directory,'train/sulphur')))
num_monarch_milkweed_tr = len(os.listdir(os.path.join(base_directory,'train/monarch-milkweed')))
#num_lyceanid_tr = len(os.listdir(os.path.join(base_directory,'train/lyceanid')))
num_cabbage_tr = len(os.listdir(os.path.join(base_directory,'train/cabbage')))
num_ringlet_tr = len(os.listdir(os.path.join(base_directory,'train/ringlet')))

#num_nymphalid_val = len(os.listdir(os.path.join(base_directory,'val/nymphalid')))
num_sulphur_val = len(os.listdir(os.path.join(base_directory,'val/sulphur')))
num_monarchmilk_val = len(os.listdir(os.path.join(base_directory,'val/monarch-milkweed')))
#num_lyceanid_val = len(os.listdir(os.path.join(base_directory,'val/lyceanid')))
num_cabbage_val = len(os.listdir(os.path.join(base_directory,'val/cabbage')))
num_ringlet_val = len(os.listdir(os.path.join(base_directory,'val/ringlet')))

total_train =  num_sulphur_tr + num_cabbage_tr + num_ringlet_tr + num_monarch_milkweed_tr
total_val =  num_sulphur_val + num_cabbage_val + num_ringlet_val + num_monarchmilk_val

#import callbacks from keras
from keras.callbacks import EarlyStopping, ModelCheckpoint

#implement callbacks to early stop training and use best model so far
early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=3)
model_checkpoint_monitor = ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)

#reset variable weights here 
model.reset_states()

#TRAIN MODEL
epochs = 30

history = model.fit_generator(
    train_data_gen,
    steps_per_epoch= int(np.ceil(train_data_gen.n / float(BATCH_SIZE))),
    epochs=epochs,
    callbacks=[early_stopping_monitor, model_checkpoint_monitor], # Early stopping
    validation_data=val_data_gen,
    validation_steps=int(np.ceil(val_data_gen.n / float(BATCH_SIZE)))
)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(early_stopping_monitor.stopped_epoch, acc, label='Training Accuracy')
plt.plot(early_stopping_monitor.stopped_epoch, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

print(test_dir)

from keras.preprocessing import image

img = image.load_img(test_dir + "/ringlet/n02277742_36182.JPEG", target_size=(150, 150))
img_tensor = image.img_to_array(img)                    # (height, width, channels)
img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)
model.predict(img_tensor)

img_tensor

plt.imshow(img_tensor[0])
plt.axis('off')
plt.show()

#TEST DIRECTORY LOSS AND ACCURACY
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(directory=test_dir, target_size = (150,150), class_mode='sparse')
test_loss, test_accuracy=model.evaluate_generator(test_generator)
print(test_loss)
print(test_accuracy)

predictions = model.predict(img_tensor)
print(predictions)
np.argmax(predictions[0])

"""SAVE MODEL:"""

import tempfile

MODEL_DIR = tempfile.gettempdir()
version = 1
export_path = os.path.join(MODEL_DIR, str(version))
print('export_path = {}\n'.format(export_path))
